## Task 1

This contains the crawler for pickaboo.com - an e-commerce site. Following are features of this spider:

#### Spider name: ***pickaboo*** 
#### Extraction fields
This crawler crawls the following fields from the website.
   - Title
  - Category
  - Product Link
  - Price
  - Image
  - Image Link
  - Stock Keeping Unit
  - Discounted Percent
  - Rating

#### Files Descriptions
***CSV file*** located in "/tmp/pick.csv" is used to store all the scraped information in an organized order. 

**Image files** are located in "tmp/images/full". All the image files are of 100x100 pixels. The image file names are default hashgenerated by Scrapy which can be linked to image_urls.

***Jupyter Notebook*** located in "/tmp/Machine Learning Ready!.ipynb" contains the example of the use of CSV file in analysis and/or research. It also includes the implementation of Machine Learning algorithm like Linear SVC, Logistic Regression etc to predict the "category" by the use of "title" for some categories are missing in the dataset.

#### Technical 
Provided you have **Python** installed
Install Scrapy
```sh
$ pip install Scrapy
```
Runing the crawler
```sh
$ scrapy crawl pickaboo
```
Runing the old crawler that has less fields and no image download
```sh
$ scrapy crawl pickaboo_old
```
